{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9f3ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from graphviz import Digraph\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f22cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node class\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature=None, threshold=None, children=None, label=None, value=None):\n",
    "        self.feature = feature #feature index for splitting\n",
    "        self.threshold = threshold #threshold value for splitting\n",
    "        self.children = children or {} #dict of child nodes\n",
    "        self.label = label #class label for leaf nodes\n",
    "        self.value = value #class dist at the node\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.label is not None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree class\n",
    "class DecisionTree:\n",
    "    def __init__(self, attributes, types):\n",
    "        self.attributes = attributes #list of attribute names\n",
    "        self.types = types #list of attribute types ('categorical' or 'continuous')\n",
    "        self.root = None #root node of the tree\n",
    "\n",
    "    def entropy(self, data):\n",
    "        if not data:\n",
    "            return 0\n",
    "        labels = [row[-1] for row in data]\n",
    "        total = len(labels)\n",
    "        count = Counter(labels)\n",
    "        return -sum((c/total) * math.log2(c/total) for c in count.values() if c > 0)\n",
    "    \n",
    "    def split_numeric(self, data, feature_idx, threshold):\n",
    "        left = [row for row in data if float(row[feature_idx]) <= threshold]\n",
    "        right = [row for row in data if float(row[feature_idx]) > threshold]\n",
    "        return left, right\n",
    "    \n",
    "    def info_gain(self, data, feature_idx, is_numeric=False):\n",
    "        if not data:\n",
    "            return -1, None\n",
    "            \n",
    "        total_entropy = self.entropy(data)\n",
    "\n",
    "        if is_numeric:\n",
    "            # Get unique values and sort them\n",
    "            values = sorted(set(float(row[feature_idx]) for row in data))\n",
    "            if len(values) <= 1:\n",
    "                return -1, None  # Can't split if only one value\n",
    "                \n",
    "            best_gain, best_threshold = -1, None\n",
    "            for i in range(len(values) - 1):\n",
    "                threshold = (values[i] + values[i+1]) / 2\n",
    "                left, right = self.split_numeric(data, feature_idx, threshold)\n",
    "                if not left or not right:\n",
    "                    continue\n",
    "                weighted_entropy = (len(left)/len(data) * self.entropy(left)) + (len(right)/len(data) * self.entropy(right))\n",
    "                gain = total_entropy - weighted_entropy\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_threshold = gain, threshold\n",
    "            return best_gain, best_threshold\n",
    "        \n",
    "        else:\n",
    "            # Categorical attribute\n",
    "            values = set(row[feature_idx] for row in data)\n",
    "            if len(values) <= 1:\n",
    "                return -1, None  # Can't split if only one value\n",
    "                \n",
    "            weighted_entropy = 0\n",
    "            for v in values:\n",
    "                subset = [row for row in data if row[feature_idx] == v]\n",
    "                if subset:  # Only calculate if subset is not empty\n",
    "                    weighted_entropy += len(subset)/len(data) * self.entropy(subset)\n",
    "            gain = total_entropy - weighted_entropy\n",
    "            return gain, None\n",
    "        \n",
    "    def best_split(self, data, attributes):\n",
    "        if not data or not attributes:\n",
    "            return None, None, None\n",
    "            \n",
    "        best_gain, best_idx, best_threshold, best_feature = -1, None, None, None\n",
    "\n",
    "        for attr in attributes:\n",
    "            feature_idx = self.attributes.index(attr)  # Get index from original attributes\n",
    "            is_numeric = self.types[attr] == 'numeric'\n",
    "            gain, threshold = self.info_gain(data, feature_idx, is_numeric)\n",
    "            \n",
    "            if gain is not None and gain > best_gain:\n",
    "                best_gain, best_idx, best_threshold, best_feature = gain, feature_idx, threshold, attr\n",
    "\n",
    "        return best_idx, best_threshold, best_feature\n",
    "    \n",
    "    def build_tree(self, data, attributes):\n",
    "        if not data:\n",
    "            return DecisionTreeNode(label=None)\n",
    "            \n",
    "        labels = [row[-1] for row in data]\n",
    "\n",
    "        # Base case 1: pure label\n",
    "        if len(set(labels)) == 1:\n",
    "            return DecisionTreeNode(label=labels[0])\n",
    "        \n",
    "        # Base case 2: no attributes left\n",
    "        if not attributes:\n",
    "            majority = Counter(labels).most_common(1)[0][0]\n",
    "            return DecisionTreeNode(label=majority)\n",
    "        \n",
    "        best_idx, best_threshold, best_attr = self.best_split(data, attributes)\n",
    "        \n",
    "        # Base case 3: no good split found\n",
    "        if best_attr is None:\n",
    "            majority = Counter(labels).most_common(1)[0][0]\n",
    "            return DecisionTreeNode(label=majority)\n",
    "\n",
    "        node = DecisionTreeNode(feature=best_attr, threshold=best_threshold)\n",
    "\n",
    "        if self.types[best_attr] == 'numeric':\n",
    "            left, right = self.split_numeric(data, best_idx, best_threshold)\n",
    "            if not left or not right:\n",
    "                majority = Counter(labels).most_common(1)[0][0]\n",
    "                return DecisionTreeNode(label=majority)\n",
    "                \n",
    "            # For numeric, we can reuse the attribute\n",
    "            node.children = {\n",
    "                f\" <= {best_threshold:.2f}\": self.build_tree(left, attributes),\n",
    "                f\" > {best_threshold:.2f}\": self.build_tree(right, attributes)\n",
    "            }\n",
    "        else:\n",
    "            # Categorical attribute\n",
    "            unique_values = set(row[best_idx] for row in data)\n",
    "            node.children = {}\n",
    "            \n",
    "            # Remove the used attribute for categorical splits\n",
    "            remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "            \n",
    "            for value in unique_values:\n",
    "                subset = [row for row in data if row[best_idx] == value]\n",
    "                if subset:\n",
    "                    node.children[value] = self.build_tree(subset, remaining_attrs)\n",
    "                else:\n",
    "                    # If no data for this value, use majority class\n",
    "                    majority = Counter(labels).most_common(1)[0][0]\n",
    "                    node.children[value] = DecisionTreeNode(label=majority)\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if not data:\n",
    "            raise ValueError(\"No data provided for training\")\n",
    "        self.root = self.build_tree(data, self.attributes[:])  # Use copy of attributes\n",
    "\n",
    "    def predict(self, sample):\n",
    "        return self._predict_node(self.root, sample)\n",
    "    \n",
    "    def _predict_node(self, node, sample):\n",
    "        if node.is_leaf():\n",
    "            return node.label\n",
    "        \n",
    "        if node.feature is None:\n",
    "            return None\n",
    "            \n",
    "        feature_idx = self.attributes.index(node.feature)\n",
    "        \n",
    "        if self.types[node.feature] == 'numeric':\n",
    "            value = float(sample[feature_idx])\n",
    "            if value <= node.threshold:\n",
    "                child_key = f\" <= {node.threshold:.2f}\"\n",
    "            else:\n",
    "                child_key = f\" > {node.threshold:.2f}\"\n",
    "                \n",
    "            if child_key in node.children:\n",
    "                return self._predict_node(node.children[child_key], sample)\n",
    "        else:\n",
    "            value = sample[feature_idx]\n",
    "            if value in node.children:\n",
    "                return self._predict_node(node.children[value], sample)\n",
    "        \n",
    "        # If we can't find a matching child, return None\n",
    "        return None\n",
    "            \n",
    "    def visualize(self, filename=\"decision_tree\"):\n",
    "        dot = Digraph()\n",
    "    \n",
    "        def add_nodes_edges(node, parent=None, edge_label=\"\"):\n",
    "            if node is None:\n",
    "                return\n",
    "            \n",
    "            # Create node label\n",
    "            if node.is_leaf():\n",
    "                label = f\"Label: {node.label}\"\n",
    "                color = \"lightblue\"\n",
    "            else:\n",
    "                if node.threshold is not None:\n",
    "                    label = f\"{node.feature}\\\\n<= {node.threshold:.2f}?\"\n",
    "                else:\n",
    "                    label = f\"{node.feature}\"\n",
    "                color = \"lightgrey\"\n",
    "\n",
    "            dot.node(str(id(node)), label=label, shape='box', style='filled', fillcolor=color)\n",
    "\n",
    "            # Add edge from parent\n",
    "            if parent is not None:\n",
    "                edge_label_str = str(edge_label) if edge_label is not None else \"\"\n",
    "                dot.edge(str(id(parent)), str(id(node)), label=edge_label_str)\n",
    "\n",
    "            # Recursively add children\n",
    "            if not node.is_leaf() and node.children:\n",
    "                for child_edge_label, child in node.children.items():\n",
    "                    add_nodes_edges(child, node, child_edge_label)\n",
    "\n",
    "        add_nodes_edges(self.root)\n",
    "        dot.render(filename, format=\"png\", cleanup=True)\n",
    "        print(f\"Tree visual saved as '{filename}.png'\")\n",
    "\n",
    "    # method to print the tree structure for debugging\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node is None:\n",
    "            print(\"Tree is empty\")\n",
    "            return\n",
    "        \n",
    "        indent = \"  \" * depth\n",
    "        if node.is_leaf():\n",
    "            print(f\"{indent}Leaf: {node.label}\")\n",
    "        else:\n",
    "            print(f\"{indent}{node.feature} (threshold: {node.threshold})\")\n",
    "            for edge_label, child in node.children.items():\n",
    "                print(f\"{indent}  -> {edge_label}:\")\n",
    "                self.print_tree(child, depth + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73816f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['ID', 'AGE', 'JOB_STATUS', 'OWNS_HOUSE', 'CREDIT_RATING', 'CLASS']\n",
      "Data shape: (15, 6)\n",
      "First few rows:\n",
      "   ID    AGE  JOB_STATUS  OWNS_HOUSE CREDIT_RATING CLASS\n",
      "0   1  Young       False       False          Fair    No\n",
      "1   2  Young       False       False          Good    No\n",
      "2   3  Young        True       False          Good   Yes\n",
      "3   4  Young        True        True          Fair   Yes\n",
      "4   5  Young       False       False          Fair    No\n",
      "First data row: ['Young', False, False, 'Fair', 'No']\n",
      "Number of samples: 15\n",
      "Root Feature: OWNS_HOUSE\n",
      "Root Threshold: None\n",
      "Root Label: None\n",
      "\n",
      "=== Tree Structure ===\n",
      "OWNS_HOUSE (threshold: None)\n",
      "  -> False:\n",
      "    JOB_STATUS (threshold: None)\n",
      "      -> False:\n",
      "        Leaf: No\n",
      "      -> True:\n",
      "        Leaf: Yes\n",
      "  -> True:\n",
      "    Leaf: Yes\n",
      "Tree visual saved as 'loan_approval_tree.png'\n",
      "Prediction for sample ['MIDDLE', 'TRUE', 'FALSE', 'GOOD']: None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data = pd.read_csv(\"Loan_Approval_Prediction.csv\")\n",
    "    \n",
    "   # inspectin data\n",
    "    print(\"Data columns:\", data.columns.tolist())\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Use the correct column names based \n",
    "    attributes = ['AGE', 'JOB_STATUS', 'OWNS_HOUSE', 'CREDIT_RATING']\n",
    "    types = {\n",
    "        'AGE': 'categorical',\n",
    "        'JOB_STATUS': 'categorical', \n",
    "        'OWNS_HOUSE': 'categorical',\n",
    "        'CREDIT_RATING': 'categorical'\n",
    "    }\n",
    "\n",
    "    # Convert to list and ensure we have the right columns\n",
    "    data_list = data[attributes + [data.columns[-1]]].values.tolist()\n",
    "    \n",
    "    print(f\"First data row: {data_list[0]}\")\n",
    "    print(f\"Number of samples: {len(data_list)}\")\n",
    "    \n",
    "    # Fit the decision tree\n",
    "    tree = DecisionTree(attributes, types)\n",
    "    tree.fit(data_list)\n",
    "    \n",
    "    print(\"Root Feature:\", tree.root.feature)\n",
    "    print(\"Root Threshold:\", tree.root.threshold)\n",
    "    print(\"Root Label:\", tree.root.label)\n",
    "    \n",
    "    # tree structure for debugging\n",
    "    print(\"\\n=== Tree Structure ===\")\n",
    "    tree.print_tree()\n",
    "    \n",
    "    # visualize\n",
    "    tree.visualize(\"loan_approval_tree\")\n",
    "\n",
    "    # Predict a sample\n",
    "    sample = ['MIDDLE', \"TRUE\", \"FALSE\", \"GOOD\"]\n",
    "    print(f\"Prediction for sample {sample}: {tree.predict(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17cf48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for ID: 0.9710\n",
      "Information Gain for AGE: 0.0830\n",
      "Information Gain for JOB_STATUS: 0.3237\n",
      "Information Gain for OWNS_HOUSE: 0.4200\n",
      "Information Gain for CREDIT_RATING: 0.3630\n",
      "\n",
      "Root Node:  ID\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(data):\n",
    "    labels = [row[-1] for row in data]\n",
    "    total = len(labels)\n",
    "    count = Counter(labels)\n",
    "    return \n",
    "\n",
    "def info_gain(data, feature_idx):\n",
    "    total_entropy = entropy(dataa)\n",
    "    values = set(row[feature] for row in data)\n",
    "    weighted_entropy = 0\n",
    "    for v in values:\n",
    "        subset = [row for row in data if row[feature_idx] == v]\n",
    "        if subset:\n",
    "            weighted_entropy += len(subset)/len(data) * entropy(subset)\n",
    "            \n",
    "    gain = total - weighted_entropy\n",
    "    return gain\n",
    "\n",
    "gain = {}\n",
    "for col in cols:\n",
    "    gain[col] = info_gain(data, col)\n",
    "\n",
    "root = max(gain, key=gain.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67588b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
