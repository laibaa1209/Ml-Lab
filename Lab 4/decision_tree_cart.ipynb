{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2590c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from graphviz import Digraph\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1591f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Node class for CART\n",
    "class CARTTreeNode:\n",
    "    def __init__(self, feature=None, threshold=None, children=None, label=None, value=None, is_leaf=False):\n",
    "        self.feature = feature  # feature index for splitting\n",
    "        self.threshold = threshold  # threshold value for splitting (for numeric features)\n",
    "        self.children = children or {}  # dict of child nodes\n",
    "        self.label = label  # class label for leaf nodes\n",
    "        self.value = value  # class distribution at the node\n",
    "        self.is_leaf = is_leaf  # explicitly track if this is a leaf node\n",
    "        self.impurity = None  # gini impurity at this node\n",
    "\n",
    "    def mark_leaf(self, label):\n",
    "        self.is_leaf = True\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f16172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from graphviz import Digraph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fixed CART Node class\n",
    "class CARTTreeNode:\n",
    "    def __init__(self, feature=None, threshold=None, children=None, label=None, value=None, is_leaf=False, impurity=None):\n",
    "        self.feature = feature  # feature index for splitting\n",
    "        self.threshold = threshold  # threshold value for splitting (for numeric features)\n",
    "        self.children = children or {}  # dict of child nodes\n",
    "        self.label = label  # class label for leaf nodes\n",
    "        self.value = value  # class distribution at the node\n",
    "        self.is_leaf = is_leaf  # explicitly track if this is a leaf node\n",
    "        self.impurity = impurity  # gini impurity at this node\n",
    "\n",
    "    def mark_leaf(self, label):\n",
    "        self.is_leaf = True\n",
    "        self.label = label\n",
    "\n",
    "# Fixed CART Decision Tree class\n",
    "class CARTDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "        self.feature_names = None\n",
    "        self.feature_types = None\n",
    "    \n",
    "    def gini_impurity(self, data):\n",
    "        \"\"\"Calculate Gini impurity for a dataset\"\"\"\n",
    "        if len(data) == 0:\n",
    "            return 0\n",
    "            \n",
    "        labels = [row[-1] for row in data]\n",
    "        total = len(labels)\n",
    "        if total == 0:\n",
    "            return 0\n",
    "            \n",
    "        count = Counter(labels)\n",
    "        return 1.0 - sum((c/total) ** 2 for c in count.values())\n",
    "    \n",
    "    def split_data(self, data, feature_idx, threshold, feature_type):\n",
    "        \"\"\"Split data based on feature and threshold\"\"\"\n",
    "        if feature_type == 'numeric':\n",
    "            left = [row for row in data if float(row[feature_idx]) <= threshold]\n",
    "            right = [row for row in data if float(row[feature_idx]) > threshold]\n",
    "            return left, right\n",
    "        else:\n",
    "            # For categorical features, split by equality\n",
    "            left = [row for row in data if row[feature_idx] == threshold]\n",
    "            right = [row for row in data if row[feature_idx] != threshold]\n",
    "            return left, right\n",
    "    \n",
    "    def find_best_split(self, data, feature_indices):\n",
    "        \"\"\"Find the best split for CART using Gini impurity\"\"\"\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_split = None\n",
    "        \n",
    "        current_gini = self.gini_impurity(data)\n",
    "        \n",
    "        for feature_idx in feature_indices:\n",
    "            feature_type = self.feature_types[feature_idx]\n",
    "            feature_values = sorted(set(row[feature_idx] for row in data))\n",
    "            \n",
    "            if feature_type == 'numeric':\n",
    "                # For numeric features, try thresholds between values\n",
    "                for i in range(len(feature_values) - 1):\n",
    "                    threshold = (float(feature_values[i]) + float(feature_values[i + 1])) / 2\n",
    "                    left, right = self.split_data(data, feature_idx, threshold, feature_type)\n",
    "                    \n",
    "                    # Check minimum samples constraint\n",
    "                    if len(left) < self.min_samples_leaf or len(right) < self.min_samples_leaf:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate weighted Gini impurity\n",
    "                    left_gini = self.gini_impurity(left)\n",
    "                    right_gini = self.gini_impurity(right)\n",
    "                    weighted_gini = (len(left) * left_gini + len(right) * right_gini) / len(data)\n",
    "                    \n",
    "                    if weighted_gini < best_gini:\n",
    "                        best_gini = weighted_gini\n",
    "                        best_feature = feature_idx\n",
    "                        best_threshold = threshold\n",
    "                        best_split = (left, right)\n",
    "            else:\n",
    "                # For categorical features, try each category as split\n",
    "                for value in feature_values:\n",
    "                    left, right = self.split_data(data, feature_idx, value, feature_type)\n",
    "                    \n",
    "                    # Check minimum samples constraint\n",
    "                    if len(left) < self.min_samples_leaf or len(right) < self.min_samples_leaf:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate weighted Gini impurity\n",
    "                    left_gini = self.gini_impurity(left)\n",
    "                    right_gini = self.gini_impurity(right)\n",
    "                    weighted_gini = (len(left) * left_gini + len(right) * right_gini) / len(data)\n",
    "                    \n",
    "                    if weighted_gini < best_gini:\n",
    "                        best_gini = weighted_gini\n",
    "                        best_feature = feature_idx\n",
    "                        best_threshold = value\n",
    "                        best_split = (left, right)\n",
    "        \n",
    "        # Only return if we found a meaningful split\n",
    "        if best_gini < current_gini:\n",
    "            return best_feature, best_threshold, best_split, best_gini\n",
    "        else:\n",
    "            return None, None, None, current_gini\n",
    "    \n",
    "    def build_tree(self, data, feature_indices, depth=0):\n",
    "        \"\"\"Recursively build the CART tree\"\"\"\n",
    "        # Base cases\n",
    "        if len(data) < self.min_samples_split:\n",
    "            return self.create_leaf_node(data)\n",
    "        \n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return self.create_leaf_node(data)\n",
    "        \n",
    "        # Check if all labels are the same\n",
    "        labels = [row[-1] for row in data]\n",
    "        if len(set(labels)) == 1:\n",
    "            return self.create_leaf_node(data)\n",
    "        \n",
    "        # Find best split\n",
    "        best_feature, best_threshold, best_split, gini = self.find_best_split(data, feature_indices)\n",
    "        \n",
    "        # If no good split found, create leaf node\n",
    "        if best_feature is None:\n",
    "            return self.create_leaf_node(data)\n",
    "        \n",
    "        left_data, right_data = best_split\n",
    "        \n",
    "        # Create node with impurity parameter\n",
    "        node = CARTTreeNode(\n",
    "            feature=best_feature,\n",
    "            threshold=best_threshold,\n",
    "            impurity=gini\n",
    "        )\n",
    "        \n",
    "        # For CART, we always do binary splits\n",
    "        feature_type = self.feature_types[best_feature]\n",
    "        \n",
    "        if feature_type == 'numeric':\n",
    "            node.children = {\n",
    "                f\" <= {best_threshold:.2f}\": self.build_tree(left_data, feature_indices, depth + 1),\n",
    "                f\" > {best_threshold:.2f}\": self.build_tree(right_data, feature_indices, depth + 1)\n",
    "            }\n",
    "        else:\n",
    "            node.children = {\n",
    "                f\" = {best_threshold}\": self.build_tree(left_data, feature_indices, depth + 1),\n",
    "                f\" ≠ {best_threshold}\": self.build_tree(right_data, feature_indices, depth + 1)\n",
    "            }\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def create_leaf_node(self, data):\n",
    "        \"\"\"Create a leaf node with the majority class\"\"\"\n",
    "        labels = [row[-1] for row in data]\n",
    "        if not labels:\n",
    "            return CARTTreeNode(is_leaf=True, label=None)\n",
    "        \n",
    "        majority_label = Counter(labels).most_common(1)[0][0]\n",
    "        return CARTTreeNode(is_leaf=True, label=majority_label)\n",
    "    \n",
    "    def fit(self, data, feature_names, feature_types):\n",
    "        \"\"\"Fit the CART tree to the data\"\"\"\n",
    "        self.feature_names = feature_names\n",
    "        self.feature_types = feature_types\n",
    "        \n",
    "        # All feature indices\n",
    "        feature_indices = list(range(len(feature_names)))\n",
    "        \n",
    "        self.root = self.build_tree(data, feature_indices)\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        \"\"\"Predict class for a single sample\"\"\"\n",
    "        return self._predict_node(self.root, sample)\n",
    "    \n",
    "    def _predict_node(self, node, sample):\n",
    "        \"\"\"Recursively traverse tree for prediction\"\"\"\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "        \n",
    "        feature_idx = node.feature\n",
    "        feature_type = self.feature_types[feature_idx]\n",
    "        feature_value = sample[feature_idx]\n",
    "        \n",
    "        if feature_type == 'numeric':\n",
    "            if float(feature_value) <= node.threshold:\n",
    "                child_key = f\" <= {node.threshold:.2f}\"\n",
    "            else:\n",
    "                child_key = f\" > {node.threshold:.2f}\"\n",
    "        else:\n",
    "            if feature_value == node.threshold:\n",
    "                child_key = f\" = {node.threshold}\"\n",
    "            else:\n",
    "                child_key = f\" ≠ {node.threshold}\"\n",
    "        \n",
    "        if child_key in node.children:\n",
    "            return self._predict_node(node.children[child_key], sample)\n",
    "        else:\n",
    "            # If child not found, return the most common label from training\n",
    "            return self._get_majority_class(node)\n",
    "    \n",
    "    def _get_majority_class(self, node):\n",
    "        \"\"\"Get majority class by traversing the tree (simplified)\"\"\"\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "        \n",
    "        # Get first available child and traverse\n",
    "        for child in node.children.values():\n",
    "            result = self._get_majority_class(child)\n",
    "            if result is not None:\n",
    "                return result\n",
    "        return None\n",
    "    \n",
    "    def visualize(self, filename=\"cart_tree\"):\n",
    "        \"\"\"Visualize the CART tree\"\"\"\n",
    "        dot = Digraph()\n",
    "        \n",
    "        def add_nodes_edges(node, parent=None, edge_label=\"\"):\n",
    "            if node is None:\n",
    "                return\n",
    "                \n",
    "            if node.is_leaf:\n",
    "                label = f\"Leaf\\\\nClass: {node.label}\"\n",
    "                color = \"lightblue\"\n",
    "                shape = \"ellipse\"\n",
    "            else:\n",
    "                feature_name = self.feature_names[node.feature]\n",
    "                if self.feature_types[node.feature] == 'numeric':\n",
    "                    label = f\"{feature_name}\\\\nGini: {node.impurity:.3f}\"\n",
    "                else:\n",
    "                    label = f\"{feature_name}\\\\nGini: {node.impurity:.3f}\"\n",
    "                color = \"lightgrey\"\n",
    "                shape = \"box\"\n",
    "            \n",
    "            dot.node(str(id(node)), label=label, shape=shape, style='filled', fillcolor=color)\n",
    "            \n",
    "            if parent is not None:\n",
    "                dot.edge(str(id(parent)), str(id(node)), label=str(edge_label))\n",
    "            \n",
    "            if not node.is_leaf:\n",
    "                for edge_label, child in node.children.items():\n",
    "                    add_nodes_edges(child, node, edge_label)\n",
    "        \n",
    "        add_nodes_edges(self.root)\n",
    "        dot.render(filename, format=\"png\", cleanup=True)\n",
    "        print(f\"CART Tree visualization saved as '{filename}.png'\")\n",
    "    \n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        \"\"\"Print tree structure for debugging\"\"\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node is None:\n",
    "            print(\"Tree is empty\")\n",
    "            return\n",
    "            \n",
    "        indent = \"  \" * depth\n",
    "        if node.is_leaf:\n",
    "            print(f\"{indent}Leaf: Class = {node.label}\")\n",
    "        else:\n",
    "            feature_name = self.feature_names[node.feature]\n",
    "            impurity_str = f\"{node.impurity:.3f}\" if node.impurity is not None else \"N/A\"\n",
    "            print(f\"{indent}{feature_name} [Gini: {impurity_str}]\")\n",
    "            for edge_label, child in node.children.items():\n",
    "                print(f\"{indent}  -> {edge_label}:\")\n",
    "                self.print_tree(child, depth + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d086800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['Student', 'Prior_Experience', 'Course', 'Time', 'Liked']\n",
      "Data shape: (10, 5)\n",
      "First few rows:\n",
      "   Student Prior_Experience       Course   Time Liked\n",
      "0        1              Yes  Programming    Day   Yes\n",
      "1        2               No  Programming    Day    No\n",
      "2        3              Yes      History  Night    No\n",
      "3        4               No  Programming  Night   Yes\n",
      "4        5              Yes      English    Day   Yes\n",
      "First data row: ['Yes', 'Programming', 'Day', 'Yes']\n",
      "Number of samples: 10\n",
      "Root Feature: Course\n",
      "Root Threshold: English\n",
      "Root Gini Impurity: 0.444\n",
      "\n",
      "=== CART Tree Structure ===\n",
      "Course [Gini: 0.444]\n",
      "  ->  = English:\n",
      "    Leaf: Class = Yes\n",
      "  ->  ≠ English:\n",
      "    Course [Gini: 0.417]\n",
      "      ->  = Mathematics:\n",
      "        Leaf: Class = Yes\n",
      "      ->  ≠ Mathematics:\n",
      "        Course [Gini: 0.429]\n",
      "          ->  = History:\n",
      "            Leaf: Class = No\n",
      "          ->  ≠ History:\n",
      "            Time [Gini: 0.405]\n",
      "              ->  = Day:\n",
      "                Prior_Experience [Gini: 0.250]\n",
      "                  ->  = No:\n",
      "                    Leaf: Class = No\n",
      "                  ->  ≠ No:\n",
      "                    Leaf: Class = Yes\n",
      "              ->  ≠ Day:\n",
      "                Prior_Experience [Gini: 0.333]\n",
      "                  ->  = No:\n",
      "                    Leaf: Class = Yes\n",
      "                  ->  ≠ No:\n",
      "                    Leaf: Class = Yes\n",
      "CART Tree visualization saved as 'student_cart_tree.png'\n",
      "\n",
      "=== Predictions on Sample Data ===\n",
      "Sample 1: ['Yes', 'Programming', 'Night'] -> Prediction: Yes\n",
      "Sample 2: ['No', 'History', 'Day'] -> Prediction: No\n",
      "Sample 3: ['Yes', 'Mathematics', 'Day'] -> Prediction: Yes\n",
      "Sample 4: ['No', 'Programming', 'Day'] -> Prediction: No\n",
      "\n",
      "=== Training Accuracy ===\n",
      "Training Accuracy: 0.80 (8/10 correct)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data = pd.read_csv(\"student.csv\")\n",
    "    \n",
    "    # inspecting data\n",
    "    print(\"Data columns:\", data.columns.tolist())\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"First few rows:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Use the correct column names based \n",
    "    attributes = ['Prior_Experience','Course','Time']\n",
    "    \n",
    "    # Define feature_types with INTEGER indices\n",
    "    feature_types = {\n",
    "        0: 'categorical',  # Prior_Experience (column 0 in data_list)\n",
    "        1: 'categorical',  # Course (column 1 in data_list) \n",
    "        2: 'categorical',  # Time (column 2 in data_list)\n",
    "    }\n",
    "\n",
    "    # Convert to list and ensure we have the right columns\n",
    "    data_list = data[attributes + [data.columns[-1]]].values.tolist()\n",
    "    \n",
    "    print(f\"First data row: {data_list[0]}\")\n",
    "    print(f\"Number of samples: {len(data_list)}\")\n",
    "    \n",
    "    # Fit the CART decision tree\n",
    "    cart_tree = CARTDecisionTree(max_depth=5, min_samples_split=2, min_samples_leaf=1)\n",
    "    cart_tree.fit(data_list, attributes, feature_types)\n",
    "    \n",
    "    if cart_tree.root:\n",
    "        if cart_tree.root.is_leaf:\n",
    "            print(\"Root Feature: Leaf Node\")\n",
    "            print(\"Root Label:\", cart_tree.root.label)\n",
    "        else:\n",
    "            print(\"Root Feature:\", cart_tree.feature_names[cart_tree.root.feature])\n",
    "            print(\"Root Threshold:\", cart_tree.root.threshold)\n",
    "            print(\"Root Gini Impurity:\", f\"{cart_tree.root.impurity:.3f}\")\n",
    "    \n",
    "    # Tree structure for debugging\n",
    "    print(\"\\n=== CART Tree Structure ===\")\n",
    "    cart_tree.print_tree()\n",
    "    \n",
    "    # Visualize\n",
    "    cart_tree.visualize(\"student_cart_tree\")\n",
    "\n",
    "    # Predict samples from the dataset\n",
    "    print(\"\\n=== Predictions on Sample Data ===\")\n",
    "    test_samples = [\n",
    "        ['Yes', 'Programming', 'Night'],\n",
    "        ['No', 'History', 'Day'],\n",
    "        ['Yes', 'Mathematics', 'Day'],\n",
    "        ['No', 'Programming', 'Day']\n",
    "    ]\n",
    "    \n",
    "    for i, sample in enumerate(test_samples):\n",
    "        prediction = cart_tree.predict(sample)\n",
    "        print(f\"Sample {i+1}: {sample} -> Prediction: {prediction}\")\n",
    "    \n",
    "    # Test accuracy on training data\n",
    "    print(\"\\n=== Training Accuracy ===\")\n",
    "    correct = 0\n",
    "    total = len(data_list)\n",
    "    \n",
    "    for i, row in enumerate(data_list):\n",
    "        features = row[:-1]  # All except last column (target)\n",
    "        actual = row[-1]     # Last column is target\n",
    "        predicted = cart_tree.predict(features)\n",
    "        \n",
    "        if predicted == actual:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Training Accuracy: {accuracy:.2f} ({correct}/{total} correct)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
